
\begin{frame}
\frametitle{Summary and future work}
\footnotesize
\begin{wideitemize}\footnotesize
\item[\highlightii{\lefthand}]  \highlightii{Descriptive arbitrariness in morphological/linguistic analysis
  can be contained} through dedicated quantitative measures
% \begin{smallwideitemize}\footnotesize
% \item Information-theoretic methods and associated tools can provide
%   objective and reproductible ways to contrast different
%   accounts of the same data on the basis of their
%   descriptive economy
% \end{smallwideitemize}
\item[\highlightii{\lefthand}] \highlightii{Moreover compact descriptions allow for uncovering system
  internal complexity}
%\pause
\item[\highlightiv{\danger}] \highlightiv{However such measures are description-dependent}\\
\ra they require the description of data within \highlightiv{a fixed
(language-independent) linguistic model}\\
\ra measures are applied to fully \highlightiv{implemented descriptions}\\
\ra associated with \highlightiv{a large or medium scale lexicon} for ensuring a
realistic picture of the data
\begin{smallwideitemize}\footnotesize
\item In our experiment, we used the \parsli model \cite{walther13phd} and its \alexinaparsli
implementation \cite{sagot13sfcm}
\end{smallwideitemize}
\item[\highlighti{\noway}] \highlighti{This measure does not provide insight into
  cognitive complexity}
%\pause
\end{wideitemize}
% \end{frame}
% \begin{frame}
% \frametitle{Perspectives}
%\pause
\highlightii{Perspectives:}
\begin{wideitemize}\footnotesize
%\item \highlightii{Perspectives}
%\begin{smallwideitemize}\footnotesize
\item[\highlightii{\leafNE}] Extension to the \highlightii{systematic comparison of
  complexity distribution} across (related) languages 
%\end{smallwideitemize}
\end{wideitemize}
\end{frame}




